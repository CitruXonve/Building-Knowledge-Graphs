{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Using RLTK to perform Entity Resolution (ER)\n",
    "\n",
    "<sub>Content of this notebook was prepared by Basel Shbita (shbita@usc.edu) as part of the class <u>CSCI 563/INF 558: Building Knowledge Graphs</u> during Spring 2020 at University of Southern California (USC).</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Record Linkage ToolKit ([RLTK](https://github.com/usc-isi-i2/rltk)) is a general-purpose open-source record linkage platform that allows users to build powerful Python programs that link records referring to the same underlying entity.\n",
    "\n",
    "This notebook introduces some applied examples using RLTK. You can also find additional examples and use-cases in [RLTK's documentation](https://rltk.readthedocs.io/en/master/)."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset analysis & RLTK components construction"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First, you need define how a single entry would like for each type of record (for each dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rltk\n",
    "\n",
    "# You can use this tokenizer in case you need to manipulate some data\n",
    "tokenizer = rltk.CrfTokenizer()\n",
    "\n",
    "# RLTK IMDB Record\n",
    "class IMDBRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['url']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def name_string(self):\n",
    "        return self.raw_object['name']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def name_tokens(self):\n",
    "        return set(tokenizer.tokenize(self.name_string))\n",
    "\n",
    "# RLTK AFI Record\n",
    "class AFIRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['url']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def name_string(self):\n",
    "        return self.raw_object['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "You can load your json-lines files into RLTK using this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_file = 'imdb.jl'\n",
    "afi_file  = 'afi.jl'\n",
    "\n",
    "# load Datasets\n",
    "ds_imdb = rltk.Dataset(reader=rltk.JsonLinesReader(imdb_file), record_class=IMDBRecord, adapter=rltk.MemoryKeyValueAdapter())\n",
    "ds_afi  = rltk.Dataset(reader=rltk.JsonLinesReader(afi_file),  record_class=AFIRecord,  adapter=rltk.MemoryKeyValueAdapter())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "And we can inspect a few entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some entries\n",
    "print(ds_imdb.generate_dataframe().head(5))\n",
    "print(ds_afi.generate_dataframe().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Field (Attribute) Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Here are 2 example functions for field (attribute) similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_string_similarity_1(r_imdb, r_afi):\n",
    "    ''' Example dummy similiary function '''\n",
    "    s1 = r_imdb.name_string[:4]\n",
    "    s2 = r_afi.name_string[:4]\n",
    "    \n",
    "    return rltk.jaro_winkler_similarity(s1, s2)\n",
    "    \n",
    "def name_string_similarity_2(r_imdb, r_afi):\n",
    "    ''' Example dummy similiary function '''\n",
    "    s1 = r_imdb.name_string[:2]\n",
    "    s2 = r_afi.name_string[:2]\n",
    "    \n",
    "    if s1 == s2:\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entity Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's how you can combine multiple similarity functions into a single weightened scoring function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold value to determine if we are confident the record match\n",
    "MY_TRESH = 0.65 # this number is just an example, you need to change it\n",
    "\n",
    "# entity linkage scoring function\n",
    "def rule_based_method(r_imdb, r_afi):\n",
    "    score_1 = name_string_similarity_1(r_imdb, r_afi)\n",
    "    score_2 = name_string_similarity_2(r_imdb, r_afi)\n",
    "    \n",
    "    total = 0.7 * score_1 + 0.3 * score_2\n",
    "    \n",
    "    # return two values: boolean if they match or not, float to determine confidence\n",
    "    return total > MY_TRESH, total"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "You can run your predictions like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on a single entry from imdb\n",
    "r_imdb = ds_imdb.get_record(\"https://www.imdb.com/title/tt0068646/\")\n",
    "r_imdb.raw_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test this record with AFI records\n",
    "for r_afi in ds_afi:\n",
    "    # get result and confidence\n",
    "    result, confidence = rule_based_method(r_imdb, r_afi)\n",
    "    #print(result, confidence)\n",
    "    if result == 1:\n",
    "        print(f'found a match (with confidence of {confidence}) based on my methods. It is: {r_afi.raw_object}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Using RDFLib for Knowledge Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDFLib is a Python library for working with RDF, a simple yet powerful language for representing information as graphs. RDFLib aims to be a pythonic RDF API, a Graph is a python collection of RDF Subject, Predicate,  Object Triples.\n",
    "\n",
    "This notebook introduces simple examples. You can also find additional information in the [official documenation](https://rdflib.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, XSD, Namespace, RDF"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's define some namespaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOAF = Namespace('http://xmlns.com/foaf/0.1/')\n",
    "MYNS = Namespace('http://inf558.org/myfakenamespace#')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can create a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg = Graph()\n",
    "my_kg.bind('myns', MYNS)\n",
    "my_kg.bind('foaf', FOAF)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define a URI, then add a simple triple to the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_uri = URIRef(MYNS['inf558_production_company'])\n",
    "my_kg.add((node_uri, RDF.type, MYNS['productionCompany']))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Add an additional triple (which describes the same subject, `node_uri`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.add((node_uri, FOAF['name'], Literal('INF 558 Production Company')))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "And now let's dump our graph triples into some `ttl` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.serialize('sample_graph.ttl', format=\"turtle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_hw03",
   "language": "python",
   "name": "kg_hw03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}