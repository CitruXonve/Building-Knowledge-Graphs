{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Using RLTK to perform Entity Resolution (ER)\n",
    "\n",
    "<sub>Content of this notebook was prepared by Basel Shbita (shbita@usc.edu) as part of the class <u>CSCI 563/INF 558: Building Knowledge Graphs</u> during Spring 2020 at University of Southern California (USC).</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Record Linkage ToolKit ([RLTK](https://github.com/usc-isi-i2/rltk)) is a general-purpose open-source record linkage platform that allows users to build powerful Python programs that link records referring to the same underlying entity.\n",
    "\n",
    "This notebook introduces some applied examples using RLTK. You can also find additional examples and use-cases in [RLTK's documentation](https://rltk.readthedocs.io/en/master/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis & RLTK components construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need define how a single entry would like for each type of record (for each dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rltk\n",
    "import json\n",
    "\n",
    "# You can use this tokenizer in case you need to manipulate some data\n",
    "tokenizer = rltk.CrfTokenizer()\n",
    "\n",
    "# RLTK IMDB Record\n",
    "class IMDBRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['url']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def name_string(self):\n",
    "        return self.raw_object['name']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def name_tokens(self):\n",
    "        return set(tokenizer.tokenize(self.name_string))\n",
    "\n",
    "# RLTK AFI Record\n",
    "class AFIRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['url']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def name_string(self):\n",
    "        return self.raw_object['title']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def date_string(self):\n",
    "        return self.raw_object.get('release_date', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load your json-lines files into RLTK using this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_file = 'imdb.jl'\n",
    "afi_file  = 'afi.jl'\n",
    "\n",
    "# load Datasets\n",
    "ds_imdb = rltk.Dataset(reader=rltk.JsonLinesReader(imdb_file), record_class=IMDBRecord, adapter=rltk.MemoryKeyValueAdapter())\n",
    "ds_afi  = rltk.Dataset(reader=rltk.JsonLinesReader(afi_file),  record_class=AFIRecord,  adapter=rltk.MemoryKeyValueAdapter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can inspect a few entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      id               name_string  \\\n",
      "0  https://www.imdb.com/title/tt0033467/              Citizen Kane   \n",
      "1  https://www.imdb.com/title/tt0068646/             The Godfather   \n",
      "2  https://www.imdb.com/title/tt0032138/          The Wizard of Oz   \n",
      "3  https://www.imdb.com/title/tt0111161/  The Shawshank Redemption   \n",
      "4  https://www.imdb.com/title/tt0110912/              Pulp Fiction   \n",
      "\n",
      "                    name_tokens  \n",
      "0               {Kane, Citizen}  \n",
      "1              {Godfather, The}  \n",
      "2         {Oz, The, Wizard, of}  \n",
      "3  {The, Shawshank, Redemption}  \n",
      "4               {Fiction, Pulp}  \n",
      "                                                  id  \\\n",
      "0  https://catalog.afi.com/#0d4edc56125f42fde0e02...   \n",
      "1  https://catalog.afi.com/#ca4bcba711e75c8e80216...   \n",
      "2  https://catalog.afi.com/#514aceac24037dcbcbd5c...   \n",
      "3  https://catalog.afi.com/#41a24923501602a537e0f...   \n",
      "4  https://catalog.afi.com/#f0bc574107fa3da879263...   \n",
      "\n",
      "                  name_string        date_string  \n",
      "0  THE PICTURE OF DORIAN GRAY  09 November, 1945  \n",
      "1             DOCTOR ZHIVAGO        09 Jan, 1965  \n",
      "2                MADAME CURIE                     \n",
      "3               MRS. MINIVER        31 May, 1942  \n",
      "4        THE GUNS OF CAVARONE               1961  \n"
     ]
    }
   ],
   "source": [
    "# print some entries\n",
    "print(ds_imdb.generate_dataframe().head(5))\n",
    "print(ds_afi.generate_dataframe().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field (Attribute) Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are 2 example functions for field (attribute) similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_string_similarity_1(r_imdb, r_afi):\n",
    "    ''' Example dummy similiary function '''\n",
    "    s1 = r_imdb.name_string[:3]\n",
    "    s2 = r_afi.name_string[:3]\n",
    "    \n",
    "    return rltk.jaro_winkler_similarity(s1, s2)\n",
    "    \n",
    "def name_string_similarity_2(r_imdb, r_afi):\n",
    "    ''' Example dummy similiary function '''\n",
    "    s1 = r_imdb.name_string\n",
    "    s2 = r_afi.name_string\n",
    "    \n",
    "    if s1 == s2:\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you can combine multiple similarity functions into a single weightened scoring function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold value to determine if we are confident the record match\n",
    "MY_TRESH = 0.8 # this number is just an example, you need to change it\n",
    "\n",
    "# entity linkage scoring function\n",
    "def rule_based_method(r_imdb, r_afi):\n",
    "    score_1 = name_string_similarity_1(r_imdb, r_afi)\n",
    "    score_2 = name_string_similarity_2(r_imdb, r_afi)\n",
    "    \n",
    "    total = 0.7 * score_1 + 0.3 * score_2\n",
    "    \n",
    "    # return two values: boolean if they match or not, float to determine confidence\n",
    "    return total > MY_TRESH, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EL Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation is a built-in module for benchmarking. Lets load our development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load development set data\n",
    "dev_set_file = 'imdb_afi_el.dev.json'\n",
    "devset_file_handle = open(dev_set_file, \"r\")\n",
    "devset_data = json.load(devset_file_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now build a ground truth based on the development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = rltk.GroundTruth()\n",
    "for item in devset_data:\n",
    "    if None != item['afi_movie']:\n",
    "        r_imdb = ds_imdb.get_record(item['imdb_movie'])\n",
    "        r_afi  = ds_afi.get_record(item['afi_movie']) \n",
    "        gt.add_positive(r_imdb.raw_object['url'], r_afi.raw_object['url'])\n",
    "gt.generate_all_negatives(ds_imdb, ds_afi, range_in_gt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run some candidates using the ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = rltk.Trial(gt)\n",
    "candidate_pairs = rltk.get_record_pairs(ds_imdb, ds_afi, ground_truth=gt)\n",
    "for r_imdb, r_afi in candidate_pairs:\n",
    "    result, confidence = rule_based_method(r_imdb, r_afi)\n",
    "    trial.add_result(r_imdb, r_afi, result, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets evaluate our trial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial statistics based on Ground-Truth from development set data:\n",
      "tp: 0.000000 [0]\n",
      "fp: 0.000000 [0]\n",
      "tn: 1.000000 [110]\n",
      "fn: 1.000000 [11]\n"
     ]
    }
   ],
   "source": [
    "trial.evaluate()\n",
    "print('Trial statistics based on Ground-Truth from development set data:')\n",
    "print(f'tp: {trial.true_positives:.06f} [{len(trial.true_positives_list)}]')\n",
    "print(f'fp: {trial.false_positives:.06f} [{len(trial.false_positives_list)}]')\n",
    "print(f'tn: {trial.true_negatives:.06f} [{len(trial.true_negatives_list)}]')\n",
    "print(f'fn: {trial.false_negatives:.06f} [{len(trial.false_negatives_list)}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Using RDFLib for Knowledge Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDFLib is a Python library for working with RDF, a simple yet powerful language for representing information as graphs. RDFLib aims to be a pythonic RDF API, a Graph is a python collection of RDF Subject, Predicate,  Object Triples.\n",
    "\n",
    "This notebook introduces simple examples. You can also find additional information in the [official documenation](https://rdflib.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, XSD, Namespace, RDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some namespaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOAF = Namespace('http://xmlns.com/foaf/0.1/')\n",
    "MYNS = Namespace('http://inf558.org/myfakenamespace#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg = Graph()\n",
    "my_kg.bind('myns', MYNS)\n",
    "my_kg.bind('foaf', FOAF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a URI, then add a simple triple to the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_uri = URIRef(MYNS['inf558_production_company'])\n",
    "my_kg.add((node_uri, RDF.type, MYNS['productionCompany']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an additional triple (which describes the same subject, `node_uri`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.add((node_uri, FOAF['name'], Literal('INF 558 Production Company')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's dump our graph triples into some `ttl` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.serialize('sample_graph.ttl', format=\"turtle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_hw03",
   "language": "python",
   "name": "kg_hw03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
