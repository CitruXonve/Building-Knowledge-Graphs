{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Snorkel to Extract Education of Actresses and Actors\n",
    "\n",
    "<sub>Content of this notebook was prepared by Basel Shbita (shbita@usc.edu) as part of the class <u>CSCI 563/INF 558: Building Knowledge Graphs</u> during Spring 2020 at University of Southern California (USC).</sub>\n",
    "\n",
    "**Notes**: \n",
    "- You are supposed to write your code or modify our code in any cell starting with `# ** STUDENT CODE`.\n",
    "- Much content of this notebook was borrowed from Snorkel Introduction Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State-of-the-art extraction techniques require massive labeled training set but it is costly to obtain. To overcome this problem, Snorkel helps rapidly create training sets using the new data programming paradigm. To start, developers focus on writing a set of labeling functions, which are just scripts that programmatically label data. The resulting labels are noisy, but Snorkel uses a generative model to learn how to use those labeling functions to label more data. The new labeled data now can be used to train high-quality end models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In summary, in this task, you will first manually label 99 documents and use these labeled data as a development set to create your own labeling functions. Then, you will train a generative model to label 1025 documents in training set. Finally, you will train a discriminative model (Bi-LSTM) to produce your final extraction model!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare environment\n",
    "\n",
    "Lets install the packages we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with Snorkel version 0.7 (Beta), we can retrieve it by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L \"https://github.com/snorkel-team/snorkel/archive/v0.7.0-beta.tar.gz\" -o snorkel_v0_7_0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's uncompress the package and install Snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf snorkel_v0_7_0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snorkel-0.7.0-beta/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a development set\n",
    "\n",
    "Before you proceed with task 1.1, we need to preprocess our documents using `Snorkel` utilities, parsing them into a simple hierarchy of component parts of our input data, which we refer as _contexts_. We'll also create _candidates_ out of these contexts, which are the objects we want to classify, in this case, possible mentions of schools and colleges that the cast have attended. Finally, we'll load some gold labels for evaluation.\n",
    "\n",
    "All of this preprocessed input data is saved to a database. In Snorkel, if no database is specified, then a SQLite database at `./snorkel.db` is created by default -- so no setup is needed here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.parser import TSVDocPreprocessor, CorpusParser\n",
    "from snorkel.parser.spacy_parser import Spacy\n",
    "from snorkel.models import Document, Sentence, candidate_subclass\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "from snorkel.annotations import LabelAnnotator, load_gold_labels\n",
    "\n",
    "from utils import reload_external_labels, save_gold_labels, save_predicted_relations, \\\n",
    "     save_gold_relations, get_dev_doc_ids, get_test_doc_ids, get_gold_labels, number_of_people\n",
    "\n",
    "# TODO: Set location where you store your homework 5 files\n",
    "if 'HW_DIR' not in os.environ:\n",
    "    # HW_DIR = Path(\"/.../Homework05\")\n",
    "    HW_DIR = Path(os.getcwd())\n",
    "else:\n",
    "    HW_DIR = Path(os.environ['HW_DIR'])\n",
    "    assert HW_DIR.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing a `SnorkelSession`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the Corpus**\n",
    "\n",
    "Next, we load and pre-process the corpus of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_preprocessor = TSVDocPreprocessor(HW_DIR / 'cast_bios.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running a `CorpusParser`**\n",
    "\n",
    "We'll use [Spacy](https://spacy.io/), an NLP preprocessing tool, to split our documents into sentences and tokens, and provide named entity annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 36.1 s, sys: 1.63 s, total: 37.7 s\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "corpus_parser = CorpusParser(parser=Spacy())\n",
    "%time corpus_parser.apply(doc_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use simple database queries (written in the syntax of [SQLAlchemy](http://www.sqlalchemy.org/), which Snorkel uses) to check how many documents and sentences were parsed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 1423\n",
      "Sentences: 8137\n"
     ]
    }
   ],
   "source": [
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating Candidates**\n",
    "\n",
    "The next step is to extract _candidates_ from our corpus. A `Candidate` in Snorkel is an object for which we want to make a prediction. In this case, the candidates are pairs of person and organization mentioned in sentences.\n",
    "\n",
    "The [Spacy](https://spacy.io/) parser we used performs _named entity recognition_ for us. Next, we'll split up the documents into train, development, and test splits; and collect the associated sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Education = candidate_subclass('Education', ['person', 'organization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import PersonMatcher, OrganizationMatcher\n",
    "\n",
    "ngrams         = Ngrams(n_max=7)\n",
    "person_matcher = PersonMatcher(longest_match_only=True)\n",
    "org_matcher    = OrganizationMatcher(longest_match_only=True)\n",
    "cand_extractor = CandidateExtractor(Education, [ngrams, ngrams], [person_matcher, org_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dev sents: 591\n",
      "Number of train sents: 5711\n",
      "Number of test sents: 1808\n"
     ]
    }
   ],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "dev_docs = get_dev_doc_ids(HW_DIR / \"cast.dev.txt\")\n",
    "test_docs = get_test_doc_ids(HW_DIR / \"cast.test.txt\")\n",
    "\n",
    "train_sents = set()\n",
    "dev_sents   = set()\n",
    "test_sents  = set()\n",
    "\n",
    "for doc in docs:\n",
    "    sents = (s for s in doc.sentences if number_of_people(s) <= 5)\n",
    "    if doc.name in dev_docs:\n",
    "        dev_sents.update(sents)\n",
    "    elif doc.name in test_docs:\n",
    "        test_sents.update(sents)\n",
    "    else:\n",
    "        train_sents.update(sents)\n",
    "        \n",
    "print(\"Number of dev sents:\", len(dev_sents))\n",
    "print(\"Number of train sents:\", len(train_sents))\n",
    "print(\"Number of test sents:\", len(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll apply the candidate extractor to the three sets of sentences. The results will be persisted in the database backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Number of candidates: 2074\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Number of candidates: 227\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Number of candidates: 537\n",
      "CPU times: user 25.8 s, sys: 397 ms, total: 26.2 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    cand_extractor.apply(sents, split=i)\n",
    "    print(\"Number of candidates:\", session.query(Education).filter(Education.split == i).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1. Label 99 documents in development set\n",
    "\n",
    "In this task, you will use `SentenceNgramViewer` to label each mention. You can click the green button to mark the candidate as correct, red button to mark as incorrect. Your labeling result is automatically stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_labels = get_gold_labels(session)\n",
    "labeled_sents = {lbl.candidate.person.sentence.id for lbl in gold_labels}\n",
    "unlabeled = [\n",
    "    x for x in session.query(Education).filter(Education.split == 1).all() \n",
    "    if x.person.sentence.id not in labeled_sents\n",
    "]\n",
    "print(\"Number unlabeled:\", len(unlabeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentenceNgramViewer(unlabeled, session, annotator_name=\"gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you finish labeling, executing the cell below to **save your result** to JSON files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 227\n",
      "AnnotatorLabels created: 537\n"
     ]
    }
   ],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "# TODO: change to your name\n",
    "# reload_external_labels(session, HW_DIR / \"Zongdi_Xu_hw05_gold_labels.dev.json\")\n",
    "save_gold_labels(session, HW_DIR / \"Zongdi_Xu_hw05_gold_labels.dev.json\", split=1)\n",
    "save_gold_relations(session, HW_DIR / \"Zongdi_Xu_hw05_extracted_relation.dev.json\", split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks 1.2 & 1.3: Define labeling functions (LFs)\n",
    "\n",
    "In this task, you will define your own LFs, which Snorkel uses to create noise-aware training set. Usually, you will go through a couple of iterations (create LFs, test and refine it) to come up with a good set of LFs. We provide you at the end of this section a helper to quickly see what candidates did your model fail to classify. You can refer to Snorkel tutorial or online documentation for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are free to use write any extra code to create a set of sophisticated LFs. For example, you build a list of universities and check if it matches with your candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** STUDENT CODE \n",
    "\n",
    "# These are some example snorkel helpers you can use...\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text, contains_token\n",
    ")\n",
    "\n",
    "\n",
    "import random, sys\n",
    "\n",
    "# TODO: Define your LFs here, below is a very simple LF\n",
    "def LF_random(c):\n",
    "    return round(random.random())\n",
    "\n",
    "def LF_distance(c):\n",
    "    return 1 if len(list(get_between_tokens(c)))<7 else -1\n",
    "\n",
    "def LF_hash(c):\n",
    "    return (hash(c.person.get_span())+hash(c.organization.get_span())+sys.maxsize) % 2 * 2 -1\n",
    "\n",
    "def LF_right_detect(c):\n",
    "    return 1 if contains_token(c, 'school') or contains_token(c, 'college') \\\n",
    "        or contains_token(c, 'university') \\\n",
    "        else -1\n",
    "\n",
    "def LF_between_detect_refined(c):\n",
    "    candidate_predicates = list(get_between_tokens(c))\n",
    "    prepositions = {'at', 'from', 'to'}\n",
    "    intransitive_predicates = {'graduated', 'studied', 'enrolled',  'went', 'returned', 'educated'}\n",
    "    transitive_predicates = {'attended'}\n",
    "    phrases = {'member', 'of'}\n",
    "    if len(transitive_predicates.intersection(candidate_predicates))>0 or \\\n",
    "        len(prepositions.intersection(candidate_predicates))>0 and \\\n",
    "            len(intransitive_predicates.intersection(candidate_predicates))>0 \\\n",
    "        or len(phrases.intersection(candidate_predicates))>1:\n",
    "        return 1 \n",
    "    return -1\n",
    "\n",
    "def LF_combined(c):\n",
    "    if LF_between_detect_refined(c)==1 and LF_right_detect(c)==1:\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "def LF_combined_refined(c):\n",
    "    taboo = {'later', 'here', 'there'}\n",
    "    if LF_combined(c)==1 and not len(taboo.intersection(get_between_tokens(c)))>0:\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# task 1.3\n",
    "def LF_distant_supervision(c):\n",
    "    if not LF_right_detect(c)==1:\n",
    "        return -1\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    sparql.setQuery(f\"\"\"\n",
    "        PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        SELECT DISTINCT ?_name ?_edu\n",
    "        WHERE {{\n",
    "            [] a dbo:Person ;\n",
    "                foaf:name ?name ;\n",
    "                dbo:almaMater [ foaf:name ?edu ] .\n",
    "            BIND(STR(?name) AS ?_name)\n",
    "            BIND(STR(?edu) AS ?_edu)\n",
    "            FILTER(REGEX(?_edu, \"(school)|(university)|(college)|(academy)\", \"i\"))\n",
    "            FILTER(REGEX(?_name, \"{'|'.join(list(map(lambda name: f'({name})', c.person.get_span().split())))}\", \"i\"))\n",
    "            # FILTER(STR(?name) = \"{c.person.get_span()}\")\n",
    "            FILTER(?_edu = \"{c.organization.get_span()}\")\n",
    "        }}\n",
    "        # LIMIT 10\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return 1 if len(results[\"results\"][\"bindings\"])>0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "# TODO: store all of your labeling functions into LFs\n",
    "\n",
    "# LFs = [LF_distance, LF_hash, LF_right_detect, LF_combined_refined]\n",
    "LFs = [LF_distance, LF_hash, LF_right_detect, LF_combined_refined, LF_distant_supervision]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train generative model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1701)\n",
    "\n",
    "labeler = LabelAnnotator(lfs=LFs)\n",
    "L_train = labeler.apply(split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n",
      "LF weights: [0.3806969  0.03181321 1.82213665 1.93364281 1.87703529]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)\n",
    "\n",
    "print(\"LF weights:\", gen_model.weights.lf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates to get the noise-aware training label set. We'll refer to these as the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the distribution of the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have learned the generative model, we will measure its performances using the provided test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n",
      "AnnotatorLabels created: 0\n"
     ]
    }
   ],
   "source": [
    "# Load test-set first\n",
    "reload_external_labels(session, HW_DIR / \"gold_labels.test.json\")\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.778\n",
      "Neg. class accuracy: 0.986\n",
      "Precision            0.824\n",
      "Recall               0.778\n",
      "F1                   0.8\n",
      "----------------------------------------\n",
      "TP: 14 | FP: 3 | TN: 206 | FN: 4\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)\n",
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get detailed statistics of LFs learned by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_distance</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>14</td>\n",
       "      <td>126</td>\n",
       "      <td>0.572687</td>\n",
       "      <td>0.672184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_hash</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0.484581</td>\n",
       "      <td>0.523581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_right_detect</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.955947</td>\n",
       "      <td>0.974169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_combined_refined</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>207</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>0.977456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>208</td>\n",
       "      <td>0.925110</td>\n",
       "      <td>0.977791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        j  Coverage  Overlaps  Conflicts  TP   FP  FN   TN  \\\n",
       "LF_distance             0       1.0       1.0   0.748899   4   83  14  126   \n",
       "LF_hash                 1       1.0       1.0   0.748899  10  109   8  100   \n",
       "LF_right_detect         2       1.0       1.0   0.748899  17    9   1  200   \n",
       "LF_combined_refined     3       1.0       1.0   0.748899  13    2   5  207   \n",
       "LF_distant_supervision  4       1.0       1.0   0.748899   2    1  16  208   \n",
       "\n",
       "                        Empirical Acc.  Learned Acc.  \n",
       "LF_distance                   0.572687      0.672184  \n",
       "LF_hash                       0.484581      0.523581  \n",
       "LF_right_detect               0.955947      0.974169  \n",
       "LF_combined_refined           0.969163      0.977456  \n",
       "LF_distant_supervision        0.925110      0.977791  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to look at some examples in one of the error buckets to improve your LFs. For example, below is one of the false negatives that we did not correctly label as true mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e640aac1afe945638c33560b7a65a2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SentenceNgramViewer(cids=[[[2], [0], [1]], [[3]]], html='<head>\\n<style>\\nspan.candidate {\\n    background-colâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SentenceNgramViewer(fn, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.4. Training an End Extraction Model\n",
    "\n",
    "In this final task, we'll use the noisy training labels we generated to train our end extraction model. In particular, we will be training a Bi-LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cands = session.query(Education).filter(Education.split == 0).order_by(Education.id).all()\n",
    "dev_cands   = session.query(Education).filter(Education.split == 1).order_by(Education.id).all()\n",
    "test_cands  = session.query(Education).filter(Education.split == 2).order_by(Education.id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try tuning the hyper-parameters below to get your best F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Training model\n",
      "[LSTM] n_train=2074  #epochs=11  batch size=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crxon/558/env/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Epoch 1 (4.98s)\tAverage loss=0.162053\tDev F1=0.00\n",
      "[LSTM] Epoch 2 (10.52s)\tAverage loss=0.116270\tDev F1=0.00\n",
      "[LSTM] Epoch 3 (16.60s)\tAverage loss=0.116469\tDev F1=0.00\n",
      "[LSTM] Epoch 4 (22.75s)\tAverage loss=0.113216\tDev F1=0.00\n",
      "[LSTM] Epoch 5 (29.10s)\tAverage loss=0.090246\tDev F1=0.00\n",
      "[LSTM] Epoch 6 (35.39s)\tAverage loss=0.049010\tDev F1=19.05\n",
      "[LSTM] Epoch 7 (41.54s)\tAverage loss=0.032666\tDev F1=57.14\n",
      "[LSTM] Epoch 8 (47.82s)\tAverage loss=0.029918\tDev F1=53.85\n",
      "[LSTM] Epoch 9 (54.20s)\tAverage loss=0.026681\tDev F1=57.14\n",
      "[LSTM] Epoch 10 (60.37s)\tAverage loss=0.021817\tDev F1=60.00\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 11 (66.57s)\tAverage loss=0.021602\tDev F1=51.61\n",
      "[LSTM] Training done (66.87s)\n",
      "[LSTM] Loaded model <LSTM>\n"
     ]
    }
   ],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "# TODO: tune your hyper-parameters for best results\n",
    "\n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':            0.009, # learning rate of the model\n",
    "    'embedding_dim': 70,   # size of the feature vector\n",
    "    'hidden_dim':    60,   # number of nodes in each layer in the model\n",
    "    'n_epochs':      11,   # number of training epochs\n",
    "    'dropout':       0.2,  # dropout rate (during learning)\n",
    "    'batch_size':    70,   # training batch size\n",
    "    'seed':          281\n",
    "}\n",
    "\n",
    "lstm = LSTM(n_threads=None)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report performance of your final extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.609, Recall: 0.400, F1 Score: 0.483\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.4\n",
      "Neg. class accuracy: 0.982\n",
      "Precision            0.609\n",
      "Recall               0.4\n",
      "F1                   0.483\n",
      "----------------------------------------\n",
      "TP: 14 | FP: 9 | TN: 493 | FN: 21\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your new model to extract relation in testing documents, and save it to JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "# TODO: change to your name\n",
    "save_predicted_relations(HW_DIR / \"Zongdi_Xu_hw05_extracted_relation.test.json\", test_cands, lstm.predictions(test_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
